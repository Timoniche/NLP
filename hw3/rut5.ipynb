{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Loading rut5 model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cd6bd1e29330f4b"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timoniche/PycharmProjects/NLP/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:53:37.443076Z",
     "start_time": "2024-03-25T22:53:36.576609Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# !pip install sentencepiece"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:53:37.882505Z",
     "start_time": "2024-03-25T22:53:37.877864Z"
    }
   },
   "id": "6ed966429eee10ce"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from_pkl_file = False\n",
    "\n",
    "tokenizer_file = 't5_tokenizer.pkl'\n",
    "model_file = 't5_model.pkl'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:53:39.205095Z",
     "start_time": "2024-03-25T22:53:39.195840Z"
    }
   },
   "id": "b963db1a60836bf7"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "user_prefix = '<u>'\n",
    "bot_prefix = '<b>'\n",
    "\n",
    "if from_pkl_file:\n",
    "    with open(tokenizer_file, 'rb') as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "else:\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\n",
    "        'cointegrated/rut5-small-chitchat2'\n",
    "    )\n",
    "    # tokenizer.add_tokens([user_prefix, bot_prefix])\n",
    "    # tokenizer.add_special_tokens({'bos_token': '<s>', 'eos_token': '</s>', 'pad_token': '<pad>'})\n",
    "\n",
    "    with open(tokenizer_file, 'wb') as f:\n",
    "        pickle.dump(tokenizer, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T23:56:27.135595Z",
     "start_time": "2024-03-25T23:56:24.255950Z"
    }
   },
   "id": "70aa2bcd0ce59da6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model: T5ForConditionalGeneration"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:53:42.026916Z",
     "start_time": "2024-03-25T22:53:42.020833Z"
    }
   },
   "id": "f60c21cc19f23d34"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "if from_pkl_file:\n",
    "    with open(model_file, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "else:\n",
    "    model = T5ForConditionalGeneration.from_pretrained('cointegrated/rut5-small-chitchat2')\n",
    "    with open(model_file, 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:53:43.511623Z",
     "start_time": "2024-03-25T22:53:42.531408Z"
    }
   },
   "id": "343887db7d04bbcb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test run"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e92b8c495dc023a3"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "text = 'Привет! Расскажи, как твои дела?'\n",
    "inputs = tokenizer(text, return_tensors='pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:53:46.011070Z",
     "start_time": "2024-03-25T22:53:46.004069Z"
    }
   },
   "id": "7498ec4c868c47ee"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # https://huggingface.co/docs/transformers/main/en/main_classes/text_generation\n",
    "    hypotheses = model.generate(\n",
    "        **inputs,\n",
    "        temperature=0.9,\n",
    "        do_sample=True,  # sampling or greedy decoding \n",
    "        # (at each decoding step selects the token with the highest prob without considering the impact on future tokens)\n",
    "        top_p=0.7,\n",
    "        num_return_sequences=3,\n",
    "        repetition_penalty=2.5,  # https://arxiv.org/pdf/1909.05858.pdf\n",
    "        max_length=32,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:53:48.039738Z",
     "start_time": "2024-03-25T22:53:47.872437Z"
    }
   },
   "id": "464c0de2783e0fd"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как?\n",
      "У меня ничего нет.\n",
      "Что это?\n"
     ]
    }
   ],
   "source": [
    "for h in hypotheses:\n",
    "    print(tokenizer.decode(h, skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:53:49.360299Z",
     "start_time": "2024-03-25T22:53:49.345792Z"
    }
   },
   "id": "cce7e0932103996a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a525955449fae8f5"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from hw3.data_preparer import load_matreshka_fort5\n",
    "\n",
    "df_train, df_val = load_matreshka_fort5()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:04.533168Z",
     "start_time": "2024-03-25T22:54:03.953531Z"
    }
   },
   "id": "2cdace7cd5acc688"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['source_text', 'target_text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:04.538191Z",
     "start_time": "2024-03-25T22:54:04.533725Z"
    }
   },
   "id": "73db5e96988be682"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def tokenize_data(data, column_name, max_length=64):\n",
    "    source_texts = data[column_name].tolist()\n",
    "    tokens = tokenizer.batch_encode_plus(\n",
    "        source_texts,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:05.334241Z",
     "start_time": "2024-03-25T22:54:05.327685Z"
    }
   },
   "id": "d9bd264f1bc3bae"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "train_tokens = tokenize_data(df_train, column_name='source_text')\n",
    "train_target_tokens = tokenize_data(df_train, column_name='target_text')\n",
    "\n",
    "val_tokens = tokenize_data(df_val, column_name='source_text')\n",
    "val_target_tokens = tokenize_data(df_val, column_name='target_text')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:09.234538Z",
     "start_time": "2024-03-25T22:54:06.421363Z"
    }
   },
   "id": "babb0ed5ee0301fd"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    train_tokens['input_ids'],\n",
    "    train_tokens['attention_mask'],\n",
    "    train_target_tokens['input_ids'],\n",
    "    train_target_tokens['attention_mask'],\n",
    ")\n",
    "\n",
    "val_dataset = TensorDataset(\n",
    "    val_tokens['input_ids'],\n",
    "    val_tokens['attention_mask'],\n",
    "    val_target_tokens['input_ids'],\n",
    "    val_target_tokens['attention_mask'],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:10.016632Z",
     "start_time": "2024-03-25T22:54:10.009961Z"
    }
   },
   "id": "f97c4d9d593161ba"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:11.330202Z",
     "start_time": "2024-03-25T22:54:11.321267Z"
    }
   },
   "id": "5ebff2de9e2d728e"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = 'mps' if torch.backends.mps.is_built() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:12.026130Z",
     "start_time": "2024-03-25T22:54:12.021146Z"
    }
   },
   "id": "f30c43cd5e31367c"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "T5ForConditionalGeneration(\n  (shared): Embedding(20100, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(20100, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 6)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedGeluDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-7): 7 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedGeluDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(20100, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 6)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedGeluDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-7): 7 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedGeluDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=20100, bias=False)\n)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:13.876977Z",
     "start_time": "2024-03-25T22:54:13.732487Z"
    }
   },
   "id": "2387891084dcc73e"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:19.249082Z",
     "start_time": "2024-03-25T22:54:18.853220Z"
    }
   },
   "id": "9b63d6d2d207e5d2"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "        model,\n",
    "        loader: DataLoader,\n",
    "        epoch,\n",
    "        num_epochs,\n",
    "        optimizer,\n",
    "        mode,\n",
    "):\n",
    "    total_loss = 0\n",
    "\n",
    "    for x_input_ids, x_attention_mask, y_input_ids, y_attention_mask in tqdm(loader,\n",
    "                                                                             desc=f'{mode} epoch {epoch}/{num_epochs}...'):\n",
    "        if mode == 'Training':\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        x_input_ids = x_input_ids.to(device)\n",
    "        x_attention_mask = x_attention_mask.to(device)\n",
    "        y_input_ids = y_input_ids.to(device)\n",
    "        y_attention_mask = y_attention_mask.to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=x_input_ids,\n",
    "            attention_mask=x_attention_mask,\n",
    "            labels=y_input_ids,\n",
    "            decoder_attention_mask=y_attention_mask,\n",
    "            return_dict=True,\n",
    "        )\n",
    "        outputs_loss = outputs.loss\n",
    "        total_loss += outputs_loss.item()\n",
    "\n",
    "        if mode == 'Training':\n",
    "            outputs_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    loss = total_loss / len(loader)\n",
    "    print(f'{mode} epoch {epoch + 1}/{num_epochs}: {mode} Loss: {loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:20.008899Z",
     "start_time": "2024-03-25T22:54:20.005552Z"
    }
   },
   "id": "d9fa2488fbb43336"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def train(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        num_epochs=5,\n",
    "):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        train_epoch(model, train_loader, epoch, num_epochs, optimizer, mode='Training')\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            train_epoch(model, val_loader, epoch, num_epochs, optimizer, mode='Validating')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:35.463895Z",
     "start_time": "2024-03-25T22:54:35.453001Z"
    }
   },
   "id": "1c233137cfb97265"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0/5...: 100%|██████████| 1858/1858 [06:58<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1/5: Training Loss: 3.3130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating epoch 0/5...: 100%|██████████| 462/462 [00:19<00:00, 23.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating epoch 1/5: Validating Loss: 1.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1/5...: 100%|██████████| 1858/1858 [06:48<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 2/5: Training Loss: 1.1510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating epoch 1/5...: 100%|██████████| 462/462 [00:19<00:00, 23.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating epoch 2/5: Validating Loss: 0.9610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 2/5...: 100%|██████████| 1858/1858 [06:48<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 3/5: Training Loss: 1.0823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating epoch 2/5...: 100%|██████████| 462/462 [00:19<00:00, 23.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating epoch 3/5: Validating Loss: 0.9284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 3/5...: 100%|██████████| 1858/1858 [06:48<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 4/5: Training Loss: 1.0429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating epoch 3/5...: 100%|██████████| 462/462 [00:19<00:00, 23.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating epoch 4/5: Validating Loss: 0.9078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 4/5...: 100%|██████████| 1858/1858 [06:49<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 5/5: Training Loss: 1.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating epoch 4/5...: 100%|██████████| 462/462 [00:19<00:00, 23.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating epoch 5/5: Validating Loss: 0.8901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T23:30:29.590033Z",
     "start_time": "2024-03-25T22:54:38.334902Z"
    }
   },
   "id": "26e7cbb4e81c1a58"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'finetuned_t5.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T23:39:44.304659Z",
     "start_time": "2024-03-25T23:39:43.419533Z"
    }
   },
   "id": "a78cdec7ff2192e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dialogue loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "511bcf33b7dc60a3"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "def generate(model: T5ForConditionalGeneration, inputs):\n",
    "    return model.generate(\n",
    "        **inputs,\n",
    "        temperature=0.9,\n",
    "        do_sample=True,\n",
    "        top_p=0.7,\n",
    "        num_return_sequences=5,\n",
    "        repetition_penalty=2.5,\n",
    "        max_length=64,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T23:59:20.089893Z",
     "start_time": "2024-03-25T23:59:20.084309Z"
    }
   },
   "id": "b0cb0d98d293aa84"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.get_vocab()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T23:59:20.548465Z",
     "start_time": "2024-03-25T23:59:20.543639Z"
    }
   },
   "id": "918d9829fb0e69ee"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([20100, 512])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['shared.weight'].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T23:59:21.132768Z",
     "start_time": "2024-03-25T23:59:21.128251Z"
    }
   },
   "id": "6f1499a6e47632e7"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Два часа.', 'Да, сегодня 20 минут.', 'Да, сегодня днем.', 'Сегодня пятница.', 'Сегодня вторник.']\n",
      "['Сегодня в отпуске.', 'Это так. Я не могу этого рассказать, но ведь все равно на самом деле мне нужно знать об этом', 'Я живу в Москве.', 'Это не так, что ты можешь мне помочь?', 'Я живу в центре города.']\n",
      "['Это город Севастополь, но сейчас на море.', 'Хорошо, в том городе.', 'Да, я тоже недавно был дома. Я могу быть в отпуске с друзьями', 'Да, я недавно был в Москве. А ты знаешь ли мы на каком-нибудь городе?', 'Я слышал, что это так.']\n",
      "['Да, это правда. А ты знаешь ли вы что-то новое?', 'Да, я в Москве. А ты знаешь ли вы?', 'Я знаю, что город Севастополь был заканчиваться на 11 часов.', 'Да, я думаю что это город сейчас в Питере.', 'Это действительно интересно. В России есть всегда много мест, чтобы в нем были проблемы со скоростью 7 минут!']\n",
      "['Интересно, какой город?', 'Это неверно. Я тоже хотел бы сказать, что этот город действительно интересно', 'Да, я не думаю об этой истории.', 'Мне кажется, что в Москве не совсем нет времени.', 'Я знаю, что у меня все отлично.']\n",
      "['Да, я тоже недавно в Питере пошел. Но это был город сейчас после 6 месяцев до 25 лет назад', 'Да, я недавно был в Питере. А как этот город?', 'Да, я недавно был в Севастополь.', 'Да, я не в курсе. Я также помню город Севастополь.', 'Это действительно интересный факт. Я не могу сказать, что город Севастополь это центр города России']\n",
      "history: <u>Сколько сейчас времени?<b>Два часа.<u>Где ты живешь?<b>Сегодня в отпуске.<u>В каком городе?<b>Это город Севастополь, но сейчас на море.<u>А в стране?<b>Да, это правда. А ты знаешь ли вы что-то новое?<u>Ошибаешься<b>Интересно, какой город?<u>WWW СПБ ЛЕНИНГРАД!!!<b>Да, я тоже недавно в Питере пошел. Но это был город сейчас после 6 месяцев до 25 лет назад\n",
      "verbose history:\n",
      "--Сколько сейчас времени?\n",
      "--Два часа.\n",
      "--Где ты живешь?\n",
      "--Сегодня в отпуске.\n",
      "--В каком городе?\n",
      "--Это город Севастополь, но сейчас на море.\n",
      "--А в стране?\n",
      "--Да, это правда. А ты знаешь ли вы что-то новое?\n",
      "--Ошибаешься\n",
      "--Интересно, какой город?\n",
      "--WWW СПБ ЛЕНИНГРАД!!!\n",
      "--Да, я тоже недавно в Питере пошел. Но это был город сейчас после 6 месяцев до 25 лет назад\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from data_preparer import ANSWER_PREFIX\n",
    "\n",
    "model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "user_input = input('Talk to bot<3')\n",
    "history = ''\n",
    "verbose_history = []\n",
    "\n",
    "while user_input != 'q':\n",
    "    user_input = user_prefix + user_input\n",
    "    history += user_input\n",
    "    inputs = tokenizer(ANSWER_PREFIX + history, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        hypotheses = generate(model, inputs)\n",
    "        bot_utterances = []\n",
    "        for h in hypotheses:\n",
    "            bot_utterances.append(tokenizer.decode(h, skip_special_tokens=True))\n",
    "        history += bot_prefix + bot_utterances[0]\n",
    "        print(bot_utterances)\n",
    "        verbose_history.append((user_input, bot_prefix + bot_utterances[0]))\n",
    "    time.sleep(1)\n",
    "    user_input = input('Talk to bot<3')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print('history:', history)\n",
    "print('verbose history:')\n",
    "for user, bot in verbose_history:\n",
    "    print('--' + user.removeprefix(user_prefix))\n",
    "    print('--' + bot.removeprefix(bot_prefix))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T00:01:55.573233Z",
     "start_time": "2024-03-26T00:00:38.316430Z"
    }
   },
   "id": "bf53ba9b57be0f93"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9609d9b14852c50"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
