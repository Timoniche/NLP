{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Loading rut5 model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cd6bd1e29330f4b"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:12:06.620071Z",
     "start_time": "2024-03-26T12:12:06.596759Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# !pip install sentencepiece"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:12:07.050137Z",
     "start_time": "2024-03-26T12:12:07.047126Z"
    }
   },
   "id": "6ed966429eee10ce"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from_pkl_file = True\n",
    "\n",
    "tokenizer_file = 't5_tokenizer.pkl'\n",
    "model_file = 't5_model.pkl'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:12:07.489984Z",
     "start_time": "2024-03-26T12:12:07.487422Z"
    }
   },
   "id": "b963db1a60836bf7"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "user_prefix = '<u>'\n",
    "bot_prefix = '<b>'\n",
    "\n",
    "if from_pkl_file:\n",
    "    with open(tokenizer_file, 'rb') as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "else:\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\n",
    "        'cointegrated/rut5-small-chitchat2'\n",
    "    )\n",
    "\n",
    "    with open(tokenizer_file, 'wb') as f:\n",
    "        pickle.dump(tokenizer, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:12:07.959941Z",
     "start_time": "2024-03-26T12:12:07.937849Z"
    }
   },
   "id": "70aa2bcd0ce59da6"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "model: T5ForConditionalGeneration"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:12:08.452427Z",
     "start_time": "2024-03-26T12:12:08.449120Z"
    }
   },
   "id": "f60c21cc19f23d34"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "if from_pkl_file:\n",
    "    with open(model_file, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "else:\n",
    "    model = T5ForConditionalGeneration.from_pretrained('cointegrated/rut5-small-chitchat2')\n",
    "    with open(model_file, 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:12:11.717758Z",
     "start_time": "2024-03-26T12:12:11.567958Z"
    }
   },
   "id": "343887db7d04bbcb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test run"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e92b8c495dc023a3"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "text = 'Привет! Расскажи, как твои дела?'\n",
    "inputs = tokenizer(text, return_tensors='pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:53:46.011070Z",
     "start_time": "2024-03-25T22:53:46.004069Z"
    }
   },
   "id": "7498ec4c868c47ee"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # https://huggingface.co/docs/transformers/main/en/main_classes/text_generation\n",
    "    hypotheses = model.generate(\n",
    "        **inputs,\n",
    "        temperature=0.9,\n",
    "        do_sample=True,  # sampling or greedy decoding \n",
    "        # (at each decoding step selects the token with the highest prob without considering the impact on future tokens)\n",
    "        top_p=0.7,\n",
    "        num_return_sequences=3,\n",
    "        repetition_penalty=2.5,  # https://arxiv.org/pdf/1909.05858.pdf\n",
    "        max_length=32,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:53:48.039738Z",
     "start_time": "2024-03-25T22:53:47.872437Z"
    }
   },
   "id": "464c0de2783e0fd"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как?\n",
      "У меня ничего нет.\n",
      "Что это?\n"
     ]
    }
   ],
   "source": [
    "for h in hypotheses:\n",
    "    print(tokenizer.decode(h, skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:53:49.360299Z",
     "start_time": "2024-03-25T22:53:49.345792Z"
    }
   },
   "id": "cce7e0932103996a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a525955449fae8f5"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from hw3.data_preparer import load_matreshka_fort5\n",
    "\n",
    "df_train, df_val = load_matreshka_fort5()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:07:50.405590Z",
     "start_time": "2024-03-26T12:07:49.622285Z"
    }
   },
   "id": "2cdace7cd5acc688"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['source_text', 'target_text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:04.538191Z",
     "start_time": "2024-03-25T22:54:04.533725Z"
    }
   },
   "id": "73db5e96988be682"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def tokenize_data(data, column_name, max_length=64):\n",
    "    source_texts = data[column_name].tolist()\n",
    "    tokens = tokenizer.batch_encode_plus(\n",
    "        source_texts,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:05.334241Z",
     "start_time": "2024-03-25T22:54:05.327685Z"
    }
   },
   "id": "d9bd264f1bc3bae"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "train_tokens = tokenize_data(df_train, column_name='source_text')\n",
    "train_target_tokens = tokenize_data(df_train, column_name='target_text')\n",
    "\n",
    "val_tokens = tokenize_data(df_val, column_name='source_text')\n",
    "val_target_tokens = tokenize_data(df_val, column_name='target_text')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:09.234538Z",
     "start_time": "2024-03-25T22:54:06.421363Z"
    }
   },
   "id": "babb0ed5ee0301fd"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    train_tokens['input_ids'],\n",
    "    train_tokens['attention_mask'],\n",
    "    train_target_tokens['input_ids'],\n",
    "    train_target_tokens['attention_mask'],\n",
    ")\n",
    "\n",
    "val_dataset = TensorDataset(\n",
    "    val_tokens['input_ids'],\n",
    "    val_tokens['attention_mask'],\n",
    "    val_target_tokens['input_ids'],\n",
    "    val_target_tokens['attention_mask'],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:10.016632Z",
     "start_time": "2024-03-25T22:54:10.009961Z"
    }
   },
   "id": "f97c4d9d593161ba"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:11.330202Z",
     "start_time": "2024-03-25T22:54:11.321267Z"
    }
   },
   "id": "5ebff2de9e2d728e"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = 'mps' if torch.backends.mps.is_built() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:12.026130Z",
     "start_time": "2024-03-25T22:54:12.021146Z"
    }
   },
   "id": "f30c43cd5e31367c"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "T5ForConditionalGeneration(\n  (shared): Embedding(20100, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(20100, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 6)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedGeluDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-7): 7 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedGeluDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(20100, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 6)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedGeluDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-7): 7 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedGeluDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=20100, bias=False)\n)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:13.876977Z",
     "start_time": "2024-03-25T22:54:13.732487Z"
    }
   },
   "id": "2387891084dcc73e"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:19.249082Z",
     "start_time": "2024-03-25T22:54:18.853220Z"
    }
   },
   "id": "9b63d6d2d207e5d2"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "        model,\n",
    "        loader: DataLoader,\n",
    "        epoch,\n",
    "        num_epochs,\n",
    "        optimizer,\n",
    "        mode,\n",
    "):\n",
    "    total_loss = 0\n",
    "\n",
    "    for x_input_ids, x_attention_mask, y_input_ids, y_attention_mask in tqdm(loader,\n",
    "                                                                             desc=f'{mode} epoch {epoch}/{num_epochs}...'):\n",
    "        if mode == 'Training':\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        x_input_ids = x_input_ids.to(device)\n",
    "        x_attention_mask = x_attention_mask.to(device)\n",
    "        y_input_ids = y_input_ids.to(device)\n",
    "        y_attention_mask = y_attention_mask.to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=x_input_ids,\n",
    "            attention_mask=x_attention_mask,\n",
    "            labels=y_input_ids,\n",
    "            decoder_attention_mask=y_attention_mask,\n",
    "            return_dict=True,\n",
    "        )\n",
    "        outputs_loss = outputs.loss\n",
    "        total_loss += outputs_loss.item()\n",
    "\n",
    "        if mode == 'Training':\n",
    "            outputs_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    loss = total_loss / len(loader)\n",
    "    print(f'{mode} epoch {epoch + 1}/{num_epochs}: {mode} Loss: {loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:15:05.202897Z",
     "start_time": "2024-03-26T12:15:05.195129Z"
    }
   },
   "id": "d9fa2488fbb43336"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def train(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        num_epochs=5,\n",
    "):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        train_epoch(model, train_loader, epoch, num_epochs, optimizer, mode='Training')\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            train_epoch(model, val_loader, epoch, num_epochs, optimizer, mode='Validating')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T22:54:35.463895Z",
     "start_time": "2024-03-25T22:54:35.453001Z"
    }
   },
   "id": "1c233137cfb97265"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0/5...: 100%|██████████| 1858/1858 [06:58<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1/5: Training Loss: 3.3130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating epoch 0/5...: 100%|██████████| 462/462 [00:19<00:00, 23.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating epoch 1/5: Validating Loss: 1.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1/5...: 100%|██████████| 1858/1858 [06:48<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 2/5: Training Loss: 1.1510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating epoch 1/5...: 100%|██████████| 462/462 [00:19<00:00, 23.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating epoch 2/5: Validating Loss: 0.9610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 2/5...: 100%|██████████| 1858/1858 [06:48<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 3/5: Training Loss: 1.0823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating epoch 2/5...: 100%|██████████| 462/462 [00:19<00:00, 23.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating epoch 3/5: Validating Loss: 0.9284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 3/5...: 100%|██████████| 1858/1858 [06:48<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 4/5: Training Loss: 1.0429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating epoch 3/5...: 100%|██████████| 462/462 [00:19<00:00, 23.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating epoch 4/5: Validating Loss: 0.9078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 4/5...: 100%|██████████| 1858/1858 [06:49<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 5/5: Training Loss: 1.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating epoch 4/5...: 100%|██████████| 462/462 [00:19<00:00, 23.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating epoch 5/5: Validating Loss: 0.8901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T23:30:29.590033Z",
     "start_time": "2024-03-25T22:54:38.334902Z"
    }
   },
   "id": "26e7cbb4e81c1a58"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'finetuned_t5.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T23:39:44.304659Z",
     "start_time": "2024-03-25T23:39:43.419533Z"
    }
   },
   "id": "a78cdec7ff2192e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dialogue loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "511bcf33b7dc60a3"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def generate(\n",
    "        model: T5ForConditionalGeneration,\n",
    "        inputs,\n",
    "        num_return_sequences=5,\n",
    "):\n",
    "    return model.generate(\n",
    "        **inputs,\n",
    "        temperature=0.9,\n",
    "        do_sample=True,\n",
    "        top_p=0.7,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        repetition_penalty=2.5,\n",
    "        max_length=64,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:16:00.926285Z",
     "start_time": "2024-03-26T12:16:00.923018Z"
    }
   },
   "id": "b0cb0d98d293aa84"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.get_vocab()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T23:59:20.548465Z",
     "start_time": "2024-03-25T23:59:20.543639Z"
    }
   },
   "id": "918d9829fb0e69ee"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([20100, 512])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['shared.weight'].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T23:59:21.132768Z",
     "start_time": "2024-03-25T23:59:21.128251Z"
    }
   },
   "id": "6f1499a6e47632e7"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Два часа.', 'Да, сегодня 20 минут.', 'Да, сегодня днем.', 'Сегодня пятница.', 'Сегодня вторник.']\n",
      "['Сегодня в отпуске.', 'Это так. Я не могу этого рассказать, но ведь все равно на самом деле мне нужно знать об этом', 'Я живу в Москве.', 'Это не так, что ты можешь мне помочь?', 'Я живу в центре города.']\n",
      "['Это город Севастополь, но сейчас на море.', 'Хорошо, в том городе.', 'Да, я тоже недавно был дома. Я могу быть в отпуске с друзьями', 'Да, я недавно был в Москве. А ты знаешь ли мы на каком-нибудь городе?', 'Я слышал, что это так.']\n",
      "['Да, это правда. А ты знаешь ли вы что-то новое?', 'Да, я в Москве. А ты знаешь ли вы?', 'Я знаю, что город Севастополь был заканчиваться на 11 часов.', 'Да, я думаю что это город сейчас в Питере.', 'Это действительно интересно. В России есть всегда много мест, чтобы в нем были проблемы со скоростью 7 минут!']\n",
      "['Интересно, какой город?', 'Это неверно. Я тоже хотел бы сказать, что этот город действительно интересно', 'Да, я не думаю об этой истории.', 'Мне кажется, что в Москве не совсем нет времени.', 'Я знаю, что у меня все отлично.']\n",
      "['Да, я тоже недавно в Питере пошел. Но это был город сейчас после 6 месяцев до 25 лет назад', 'Да, я недавно был в Питере. А как этот город?', 'Да, я недавно был в Севастополь.', 'Да, я не в курсе. Я также помню город Севастополь.', 'Это действительно интересный факт. Я не могу сказать, что город Севастополь это центр города России']\n",
      "history: <u>Сколько сейчас времени?<b>Два часа.<u>Где ты живешь?<b>Сегодня в отпуске.<u>В каком городе?<b>Это город Севастополь, но сейчас на море.<u>А в стране?<b>Да, это правда. А ты знаешь ли вы что-то новое?<u>Ошибаешься<b>Интересно, какой город?<u>WWW СПБ ЛЕНИНГРАД!!!<b>Да, я тоже недавно в Питере пошел. Но это был город сейчас после 6 месяцев до 25 лет назад\n",
      "verbose history:\n",
      "--Сколько сейчас времени?\n",
      "--Два часа.\n",
      "--Где ты живешь?\n",
      "--Сегодня в отпуске.\n",
      "--В каком городе?\n",
      "--Это город Севастополь, но сейчас на море.\n",
      "--А в стране?\n",
      "--Да, это правда. А ты знаешь ли вы что-то новое?\n",
      "--Ошибаешься\n",
      "--Интересно, какой город?\n",
      "--WWW СПБ ЛЕНИНГРАД!!!\n",
      "--Да, я тоже недавно в Питере пошел. Но это был город сейчас после 6 месяцев до 25 лет назад\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from data_preparer import ANSWER_PREFIX\n",
    "\n",
    "model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "user_input = input('Talk to bot<3')\n",
    "history = ''\n",
    "verbose_history = []\n",
    "\n",
    "while user_input != 'q':\n",
    "    user_input = user_prefix + user_input\n",
    "    history += user_input\n",
    "    inputs = tokenizer(ANSWER_PREFIX + history, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        hypotheses = generate(model, inputs)\n",
    "        bot_utterances = []\n",
    "        for h in hypotheses:\n",
    "            bot_utterances.append(tokenizer.decode(h, skip_special_tokens=True))\n",
    "        history += bot_prefix + bot_utterances[0]\n",
    "        print(bot_utterances)\n",
    "        verbose_history.append((user_input, bot_prefix + bot_utterances[0]))\n",
    "    time.sleep(1)\n",
    "    user_input = input('Talk to bot<3')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print('history:', history)\n",
    "print('verbose history:')\n",
    "for user, bot in verbose_history:\n",
    "    print('--' + user.removeprefix(user_prefix))\n",
    "    print('--' + bot.removeprefix(bot_prefix))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T00:01:55.573233Z",
     "start_time": "2024-03-26T00:00:38.316430Z"
    }
   },
   "id": "bf53ba9b57be0f93"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Considering BLEU score(?!)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b60d5818b990b9bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Usage example"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "928ec7112714b75b"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.7598)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.text import BLEUScore\n",
    "\n",
    "# A BLEU score of 0.4 or higher is generally considered good (answer from GPT)\n",
    "\n",
    "preds = ['the cat is on the mat']\n",
    "target = [['there is a cat on the mat', 'a cat is on the mat']]\n",
    "bleu = BLEUScore()\n",
    "bleu(preds, target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:06:43.671434Z",
     "start_time": "2024-03-26T12:06:43.666959Z"
    }
   },
   "id": "9609d9b14852c50"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            source_text  \\\n",
      "0     ответь: Но как же все, что было раньше? Мы же ...   \n",
      "1     ответь: Ой, было ужасно, я проспал все выходны...   \n",
      "2        ответь: Да вечеринка была и я уснул на диване.   \n",
      "3     ответь: Привет, я наконец-то вернулся после до...   \n",
      "4     ответь: Я побывал во многих странах, в том чис...   \n",
      "...                                                 ...   \n",
      "3691                                    ответь: Привет!   \n",
      "3692    ответь: Я хочу узнать факты о пандемии COVID-19   \n",
      "3693                ответь: Вот это да, а факт номер 2?   \n",
      "3694    ответь: В России насчитывается более 19000 озер   \n",
      "3695  ответь: В России находится самая высокая гора ...   \n",
      "\n",
      "                                            target_text  \n",
      "0     Да, но это может быть лучше, чем продолжать жи...  \n",
      "1                                Что же ты так проспал?  \n",
      "2     Надеюсь, тебе не пришлось что-то важное пропус...  \n",
      "3             О, привет! Какое путешествие ты проходил?  \n",
      "4     Звучит интересно! Что тебе больше всего запомн...  \n",
      "...                                                 ...  \n",
      "3691               Здравствуйте, как я могу Вам помочь?  \n",
      "3692  Конечно, факт номер 1: на сегодняшний день общ...  \n",
      "3693  Второй факт: более 840 тысяч человек по всему ...  \n",
      "3694  Озеро Байкал является самым глубоким озером в ...  \n",
      "3695  Самый большой город России - Москва, население...  \n",
      "\n",
      "[3696 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:07:54.387555Z",
     "start_time": "2024-03-26T12:07:54.383812Z"
    }
   },
   "id": "bd873e047bc2d329"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "T5ForConditionalGeneration(\n  (shared): Embedding(20100, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(20100, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 6)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedGeluDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-7): 7 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedGeluDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(20100, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 6)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedGeluDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-7): 7 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedGeluDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=20100, bias=False)\n)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('finetuned_t5.pth'))\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:14:37.354560Z",
     "start_time": "2024-03-26T12:14:37.177326Z"
    }
   },
   "id": "b8e322c04ff40ee9"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Е е е', ' еее', 'еее']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "string = 'Е е е? еее.еее'\n",
    "string_splitted = re.split('\\.|\\?', string)\n",
    "print(string_splitted)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:57:41.517557Z",
     "start_time": "2024-03-26T12:57:41.504397Z"
    }
   },
   "id": "b0ab1bfd79ef04a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating BLEU on val dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ebb2982462fb9b"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg bleu: 0.13365166932344436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from torchmetrics.text import BLEUScore\n",
    "\n",
    "bleu = BLEUScore(n_gram=1)\n",
    "avg_bleu_score = 0.\n",
    "cnt = 100\n",
    "with torch.no_grad():\n",
    "    for _, row in tqdm(df_val.head(cnt).iterrows(), total=cnt):\n",
    "        source = row['source_text']\n",
    "        target = row['target_text']\n",
    "\n",
    "        inputs = tokenizer(source, return_tensors='pt')\n",
    "        hypotheses = generate(model, inputs, num_return_sequences=1)\n",
    "        pred = tokenizer.decode(hypotheses[0], skip_special_tokens=True)\n",
    "\n",
    "        shrinked_target = re.split('\\.|\\?', target)[0]\n",
    "        shrinked_pred = re.split('\\.|\\?', pred)[0]\n",
    "        \n",
    "        metric = bleu(shrinked_pred, shrinked_target)\n",
    "        avg_bleu_score += metric.item()\n",
    "print('avg bleu:', avg_bleu_score * 1. / cnt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T13:01:51.831041Z",
     "start_time": "2024-03-26T13:01:40.367030Z"
    }
   },
   "id": "6b9d92b230477dbe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Considering METEOR metric"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a944679df9fc9e45"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Usage example"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa7a8dedd5213199"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/timoniche/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/timoniche/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/timoniche/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "meteor = evaluate.load('meteor')\n",
    "predictions = [\"It is a guide to action which ensures that the military always obeys the commands of the party\"]\n",
    "reference = [\"It is a guide to action which ensures that the military always obeys the commands of the party\"]\n",
    "results = meteor.compute(predictions=predictions, references=reference)\n",
    "print(round(results['meteor'], 2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:46:14.664373Z",
     "start_time": "2024-03-26T20:46:13.328103Z"
    }
   },
   "id": "df37b988115dac80"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating METEOR on val dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e359e73a2b5ad983"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:17<00:00,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg meteor: 0.14073682317052313\n",
      "avg initial meteor: 0.03196982772392597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "avg_meteor_score = 0.\n",
    "initial_meteor_score = 0.\n",
    "\n",
    "cnt = 100\n",
    "initial_model = T5ForConditionalGeneration.from_pretrained('cointegrated/rut5-small-chitchat2')\n",
    "with torch.no_grad():\n",
    "    for _, row in tqdm(df_val.head(cnt).iterrows(), total=cnt):\n",
    "        source = row['source_text']\n",
    "        target = row['target_text']\n",
    "\n",
    "        inputs = tokenizer(source, return_tensors='pt')\n",
    "        hypotheses = generate(model, inputs, num_return_sequences=1)\n",
    "        not_fine_tuned_hypotheses = generate(initial_model, inputs, num_return_sequences=1)\n",
    "        \n",
    "        pred = tokenizer.decode(hypotheses[0], skip_special_tokens=True)\n",
    "        not_fine_tuned_preds = tokenizer.decode(not_fine_tuned_hypotheses[0], skip_special_tokens=True)\n",
    "        \n",
    "        shrinked_target = re.split('\\.|\\?', target)[0]\n",
    "        shrinked_pred = re.split('\\.|\\?', pred)[0]\n",
    "        shinked_initial_preds = re.split('\\.|\\?', not_fine_tuned_preds)[0]\n",
    "        \n",
    "        metric = meteor.compute(predictions=[shrinked_pred], references=[shrinked_target])\n",
    "        initial_metric = meteor.compute(predictions=[shinked_initial_preds], references=[shrinked_target])\n",
    "        \n",
    "        avg_meteor_score += metric['meteor']\n",
    "        initial_meteor_score += initial_metric['meteor']\n",
    "        \n",
    "print('avg meteor:', avg_meteor_score * 1. / cnt)\n",
    "print('avg initial meteor:', initial_meteor_score * 1. / cnt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:57:22.051224Z",
     "start_time": "2024-03-26T20:57:02.860421Z"
    }
   },
   "id": "f3edc5a4f07aded9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b5895630bdd12173"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
